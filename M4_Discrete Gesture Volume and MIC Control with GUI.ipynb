{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d91924b-2675-4ee9-a665-d5f6f75feeea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\AppData\\Roaming\\Python\\Python310\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping video processor thread and closing application...\n"
     ]
    }
   ],
   "source": [
    "#VOLUME CONTROL\n",
    "import sys\n",
    "import platform\n",
    "import threading\n",
    "from ctypes import POINTER, cast\n",
    "from functools import wraps\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import tkinter as tk\n",
    "from tkinter import ttk, Scale, Button, HORIZONTAL, StringVar, W, E, Label\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "try:\n",
    "    if platform.system() != \"Windows\":\n",
    "        raise SystemExit(\"This script runs only on Windows.\")\n",
    "\n",
    "    from comtypes import CLSCTX_ALL, CoInitialize, CoUninitialize, GUID\n",
    "    from comtypes.client import CreateObject\n",
    "    from pycaw.pycaw import IAudioEndpointVolume, IMMDeviceEnumerator\n",
    "\n",
    "except ImportError as e:\n",
    "    print(\"Error: Missing pycaw, comtypes, or other required packages. Did you run 'pip install pycaw comtypes opencv-python mediapipe Pillow'?\", file=sys.stderr)\n",
    "    raise SystemExit(f\"Required component import failed: {e}\")\n",
    "\n",
    "eRender = 0\n",
    "eMultimedia = 1\n",
    "\n",
    "def ensure_com(func):\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        CoInitialize()\n",
    "        try:\n",
    "            return func(*args, **kwargs)\n",
    "        except Exception as e:\n",
    "            print(f\"Exception in COM handler ({func.__name__}): {e}\", file=sys.stderr)\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "        finally:\n",
    "            CoUninitialize()\n",
    "    return wrapper\n",
    "\n",
    "def _create_mmdevice_enumerator():\n",
    "    try:\n",
    "        return CreateObject(\"MMDeviceEnumerator.MMDeviceEnumerator\", interface=IMMDeviceEnumerator)\n",
    "    except Exception:\n",
    "        clsid = GUID(\"{BCDE0395-E52F-467C-8E3D-C4579291692E}\")\n",
    "        return CreateObject(clsid, interface=IMMDeviceEnumerator)\n",
    "\n",
    "@ensure_com\n",
    "def _get_volume_interface_for_default():\n",
    "    enumerator = _create_mmdevice_enumerator()\n",
    "    default_device = enumerator.GetDefaultAudioEndpoint(eRender, eMultimedia)\n",
    "    iface = default_device.Activate(IAudioEndpointVolume._iid_, CLSCTX_ALL, None)\n",
    "    return cast(iface, POINTER(IAudioEndpointVolume))\n",
    "\n",
    "def _percent_to_scalar(p):\n",
    "    return max(0.0, min(1.0, p / 100.0))\n",
    "\n",
    "def _scalar_to_percent(s):\n",
    "    return max(0.0, min(100.0, s * 100.0))\n",
    "\n",
    "class PycawVolumeHandler:\n",
    "    @ensure_com\n",
    "    def get_initial_state(self):\n",
    "        vol = _get_volume_interface_for_default()\n",
    "        cur_scalar = float(vol.GetMasterVolumeLevelScalar())\n",
    "        cur_pct = round(_scalar_to_percent(cur_scalar))\n",
    "        is_muted = bool(vol.GetMute())\n",
    "        return cur_pct, is_muted\n",
    "\n",
    "    @ensure_com\n",
    "    def set_volume_and_handle_mute(self, new_pct, current_is_muted):\n",
    "        vol = _get_volume_interface_for_default()\n",
    "        \n",
    "        vol.SetMasterVolumeLevelScalar(_percent_to_scalar(new_pct), None)\n",
    "        \n",
    "        new_is_muted = current_is_muted\n",
    "        if new_pct == 0:\n",
    "            if not current_is_muted:\n",
    "                vol.SetMute(1, None)\n",
    "                new_is_muted = True\n",
    "        elif new_pct > 0 and current_is_muted:\n",
    "            vol.SetMute(0, None)\n",
    "            new_is_muted = False\n",
    "            \n",
    "        return new_is_muted\n",
    "\n",
    "    @ensure_com\n",
    "    def toggle_mute_state(self, current_is_muted):\n",
    "        vol = _get_volume_interface_for_default()\n",
    "        new_is_muted = not current_is_muted\n",
    "        vol.SetMute(1 if new_is_muted else 0, None)\n",
    "        return new_is_muted\n",
    "\n",
    "class VideoProcessor(threading.Thread):\n",
    "    \n",
    "    FINGER_TIP_IDS = [mp.solutions.hands.HandLandmark.INDEX_FINGER_TIP, \n",
    "                      mp.solutions.hands.HandLandmark.MIDDLE_FINGER_TIP, \n",
    "                      mp.solutions.hands.HandLandmark.RING_FINGER_TIP, \n",
    "                      mp.solutions.hands.HandLandmark.PINKY_TIP]\n",
    "    \n",
    "    FINGER_PIP_IDS = [mp.solutions.hands.HandLandmark.INDEX_FINGER_PIP, \n",
    "                      mp.solutions.hands.HandLandmark.MIDDLE_FINGER_PIP, \n",
    "                      mp.solutions.hands.HandLandmark.RING_FINGER_PIP, \n",
    "                      mp.solutions.hands.HandLandmark.PINKY_PIP]\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        self.running = True\n",
    "        \n",
    "        self.mp_hands = mp.solutions.hands\n",
    "        self.hands = self.mp_hands.Hands(\n",
    "            static_image_mode=False, \n",
    "            model_complexity=1, \n",
    "            min_detection_confidence=0.5,\n",
    "            min_tracking_confidence=0.5,\n",
    "            max_num_hands=1\n",
    "        )\n",
    "        self.mp_drawing = mp.solutions.drawing_utils\n",
    "        \n",
    "        self.current_frame = None\n",
    "        self.volume_pct = 0\n",
    "        self.distance_text = \"Fingers: N/A\" \n",
    "        self.volume_changed = False\n",
    "\n",
    "    def _count_extended_fingers(self, hand_landmarks):\n",
    "        finger_count = 0\n",
    "        \n",
    "        lm_thumb_tip = hand_landmarks.landmark[mp.solutions.hands.HandLandmark.THUMB_TIP]\n",
    "        lm_thumb_mcp = hand_landmarks.landmark[mp.solutions.hands.HandLandmark.THUMB_MCP]\n",
    "        \n",
    "        if lm_thumb_tip.x < lm_thumb_mcp.x:\n",
    "            finger_count += 1\n",
    "            \n",
    "        for tip_id, pip_id in zip(self.FINGER_TIP_IDS, self.FINGER_PIP_IDS):\n",
    "            lm_tip = hand_landmarks.landmark[tip_id]\n",
    "            lm_pip = hand_landmarks.landmark[pip_id]\n",
    "            \n",
    "            if lm_tip.y < lm_pip.y:\n",
    "                finger_count += 1\n",
    "                \n",
    "        return finger_count\n",
    "\n",
    "    def run(self):\n",
    "        self.cap = cv2.VideoCapture(0)\n",
    "        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "        \n",
    "        frame_width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        frame_height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        \n",
    "        while self.running:\n",
    "            success, img = self.cap.read()\n",
    "            if not success:\n",
    "                time.sleep(0.01)\n",
    "                continue\n",
    "\n",
    "            img = cv2.flip(img, 1)\n",
    "            imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            results = self.hands.process(imgRGB)\n",
    "            \n",
    "            self.volume_changed = False\n",
    "            new_volume_pct = self.volume_pct\n",
    "\n",
    "            if results.multi_hand_landmarks:\n",
    "                hand_landmarks = results.multi_hand_landmarks[0]\n",
    "                \n",
    "                finger_count = self._count_extended_fingers(hand_landmarks)\n",
    "                \n",
    "                new_volume_pct = int(finger_count * 20)\n",
    "                \n",
    "                lm_wrist = hand_landmarks.landmark[mp.solutions.hands.HandLandmark.WRIST]\n",
    "                wx, wy = int(lm_wrist.x * frame_width), int(lm_wrist.y * frame_height)\n",
    "                cv2.circle(img, (wx, wy), 10, (0, 255, 0), cv2.FILLED)\n",
    "                \n",
    "                self.mp_drawing.draw_landmarks(img, hand_landmarks, self.mp_hands.HAND_CONNECTIONS)\n",
    "                cv2.putText(img, f'VOL: {new_volume_pct}%', (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "                self.distance_text = f\"Fingers: {finger_count}/5\"\n",
    "                self.volume_changed = True\n",
    "\n",
    "            else:\n",
    "                self.distance_text = \"Fingers: No Hand Detected\"\n",
    "\n",
    "            self.current_frame = img\n",
    "            self.volume_pct = new_volume_pct\n",
    "            \n",
    "            time.sleep(0.02)\n",
    "\n",
    "    def stop(self):\n",
    "        self.running = False\n",
    "        if hasattr(self, 'cap') and self.cap.isOpened():\n",
    "            self.cap.release()\n",
    "\n",
    "class GestureVolumeApp:\n",
    "    def __init__(self, window, window_title):\n",
    "        self.window = window\n",
    "        self.window.title(window_title)\n",
    "        \n",
    "        self.volume_handler = PycawVolumeHandler()\n",
    "        self.current_volume_pct, self.is_muted = self.volume_handler.get_initial_state()\n",
    "        \n",
    "        self.processor = VideoProcessor()\n",
    "        self.processor.start()\n",
    "        \n",
    "        self.setup_gui()\n",
    "        \n",
    "        self.delay = 30\n",
    "        self.update()\n",
    "\n",
    "        self.window.protocol(\"WM_DELETE_WINDOW\", self.on_closing)\n",
    "        self.window.mainloop()\n",
    "\n",
    "    def setup_gui(self):\n",
    "        self.distance_var = tk.StringVar(self.window, value=\"Fingers: N/A\")\n",
    "        self.volume_var = tk.StringVar(self.window, value=str(self.current_volume_pct))\n",
    "        self.mute_text_var = tk.StringVar(self.window)\n",
    "        \n",
    "        style = ttk.Style()\n",
    "        style.theme_use('clam')\n",
    "        \n",
    "        main_frame = ttk.Frame(self.window, padding=\"10 10 10 10\")\n",
    "        main_frame.pack(fill='both', expand=True)\n",
    "        \n",
    "        self.video_label = ttk.Label(main_frame, borderwidth=2, relief=\"groove\")\n",
    "        self.video_label.pack(pady=10)\n",
    "        \n",
    "        Label(main_frame, text=\"System Volume:\").pack(pady=(5, 0))\n",
    "        self.volume_scale = Scale(\n",
    "            main_frame, \n",
    "            from_=0, to=100, orient=HORIZONTAL, length=300, resolution=1,\n",
    "            variable=self.volume_var, state='disabled',\n",
    "            troughcolor=\"#A0E0FF\", highlightbackground=\"#CCCCCC\"\n",
    "        )\n",
    "        self.volume_scale.pack(pady=5)\n",
    "        \n",
    "        distance_frame = ttk.Frame(main_frame)\n",
    "        distance_frame.pack(fill='x', pady=5)\n",
    "        ttk.Label(distance_frame, text=\"Finger Count:\", font=('Arial', 12)).pack(side='left', padx=(20, 5)) \n",
    "        self.distance_info_label = ttk.Label(\n",
    "            distance_frame, textvariable=self.distance_var,\n",
    "            font=('Arial', 14, 'bold'), foreground='#1E88E5'\n",
    "        )\n",
    "        self.distance_info_label.pack(side='left', fill='x', expand=True)\n",
    "\n",
    "        self.mute_button = Button(\n",
    "            main_frame, textvariable=self.mute_text_var, command=self.toggle_mute,\n",
    "            fg=\"white\", relief=\"raised\", font=('Arial', 10, 'bold')\n",
    "        )\n",
    "        self.mute_button.pack(fill='x', pady=10)\n",
    "        \n",
    "        self._update_mute_button_text()\n",
    "        \n",
    "        ttk.Label(\n",
    "            main_frame, \n",
    "            text=\"Control volume by the number of fingers extended (0=0%, 5=100%).\",\n",
    "            font=('Arial', 10, 'italic')\n",
    "        ).pack(pady=5)\n",
    "\n",
    "\n",
    "    def _update_mute_button_text(self):\n",
    "        if self.is_muted:\n",
    "            self.mute_text_var.set(\"UNMUTE (Muted)\")\n",
    "            self.mute_button.config(bg=\"#FF6666\", activebackground=\"#DD4444\")\n",
    "        else:\n",
    "            self.mute_text_var.set(\"MUTE (Active)\")\n",
    "            self.mute_button.config(bg=\"#66FF66\", activebackground=\"#44DD44\")\n",
    "            \n",
    "    def toggle_mute(self):\n",
    "        self.is_muted = self.volume_handler.toggle_mute_state(self.is_muted)\n",
    "        self._update_mute_button_text()\n",
    "\n",
    "\n",
    "    def update(self):\n",
    "        \n",
    "        if self.processor.current_frame is not None:\n",
    "            img = self.processor.current_frame\n",
    "            self.photo = ImageTk.PhotoImage(image=Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)))\n",
    "            self.video_label.config(image=self.photo)\n",
    "            \n",
    "            self.distance_var.set(self.processor.distance_text)\n",
    "\n",
    "        if self.processor.volume_changed:\n",
    "            new_volume_pct = self.processor.volume_pct\n",
    "            \n",
    "            self.volume_var.set(str(new_volume_pct))\n",
    "            \n",
    "            self.is_muted = self.volume_handler.set_volume_and_handle_mute(\n",
    "                new_volume_pct, self.is_muted\n",
    "            )\n",
    "            self.processor.volume_changed = False\n",
    "            self._update_mute_button_text()\n",
    "            \n",
    "        self.window.after(self.delay, self.update)\n",
    "        \n",
    "    def on_closing(self):\n",
    "        print(\"Stopping video processor thread and closing application...\")\n",
    "        self.processor.stop()\n",
    "        self.processor.join()\n",
    "        cv2.destroyAllWindows()\n",
    "        self.window.destroy()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = GestureVolumeApp(root, \"Gesture Volume Control (Finger Count)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f25d5fc-0239-4fcd-8b21-d65e3be0a065",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\AppData\\Roaming\\Python\\Python310\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping video processor thread and closing application...\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import platform\n",
    "import threading\n",
    "from ctypes import POINTER, cast\n",
    "from functools import wraps\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import tkinter as tk\n",
    "from tkinter import ttk, Scale, Button, HORIZONTAL, StringVar, W, E, Label\n",
    "from PIL import Image, ImageTk\n",
    "\n",
    "try:\n",
    "    if platform.system() != \"Windows\":\n",
    "        raise SystemExit(\"This script runs only on Windows.\")\n",
    "\n",
    "    from comtypes import CLSCTX_ALL, CoInitialize, CoUninitialize, GUID\n",
    "    from comtypes.client import CreateObject\n",
    "    from pycaw.pycaw import IAudioEndpointVolume, IMMDeviceEnumerator\n",
    "\n",
    "except ImportError as e:\n",
    "    print(\"Error: Missing pycaw, comtypes, or other required packages. Did you run 'pip install pycaw comtypes opencv-python mediapipe Pillow'?\", file=sys.stderr)\n",
    "    raise SystemExit(f\"Required component import failed: {e}\")\n",
    "\n",
    "eCapture = 1\n",
    "eMultimedia = 1\n",
    "\n",
    "def ensure_com(func):\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        CoInitialize()\n",
    "        try:\n",
    "            return func(*args, **kwargs)\n",
    "        except Exception as e:\n",
    "            print(f\"Exception in COM handler ({func.__name__}): {e}\", file=sys.stderr)\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "        finally:\n",
    "            CoUninitialize()\n",
    "    return wrapper\n",
    "\n",
    "def _create_mmdevice_enumerator():\n",
    "    try:\n",
    "        return CreateObject(\"MMDeviceEnumerator.MMDeviceEnumerator\", interface=IMMDeviceEnumerator)\n",
    "    except Exception:\n",
    "        clsid = GUID(\"{BCDE0395-E52F-467C-8E3D-C4579291692E}\")\n",
    "        return CreateObject(clsid, interface=IMMDeviceEnumerator)\n",
    "\n",
    "@ensure_com\n",
    "def _get_volume_interface_for_default():\n",
    "    enumerator = _create_mmdevice_enumerator()\n",
    "    default_device = enumerator.GetDefaultAudioEndpoint(eCapture, eMultimedia)\n",
    "    iface = default_device.Activate(IAudioEndpointVolume._iid_, CLSCTX_ALL, None)\n",
    "    return cast(iface, POINTER(IAudioEndpointVolume))\n",
    "\n",
    "def _percent_to_scalar(p):\n",
    "    return max(0.0, min(1.0, p / 100.0))\n",
    "\n",
    "def _scalar_to_percent(s):\n",
    "    return max(0.0, min(100.0, s * 100.0))\n",
    "\n",
    "class PycawVolumeHandler:\n",
    "    @ensure_com\n",
    "    def get_initial_state(self):\n",
    "        vol = _get_volume_interface_for_default()\n",
    "        cur_scalar = float(vol.GetMasterVolumeLevelScalar())\n",
    "        cur_pct = round(_scalar_to_percent(cur_scalar))\n",
    "        is_muted = bool(vol.GetMute())\n",
    "        return cur_pct, is_muted\n",
    "\n",
    "    @ensure_com\n",
    "    def set_volume_and_handle_mute(self, new_pct, current_is_muted):\n",
    "        vol = _get_volume_interface_for_default()\n",
    "        \n",
    "        vol.SetMasterVolumeLevelScalar(_percent_to_scalar(new_pct), None)\n",
    "        \n",
    "        new_is_muted = current_is_muted\n",
    "        if new_pct == 0:\n",
    "            if not current_is_muted:\n",
    "                vol.SetMute(1, None)\n",
    "                new_is_muted = True\n",
    "        elif new_pct > 0 and current_is_muted:\n",
    "            vol.SetMute(0, None)\n",
    "            new_is_muted = False\n",
    "            \n",
    "        return new_is_muted\n",
    "\n",
    "    @ensure_com\n",
    "    def toggle_mute_state(self, current_is_muted):\n",
    "        vol = _get_volume_interface_for_default()\n",
    "        new_is_muted = not current_is_muted\n",
    "        vol.SetMute(1 if new_is_muted else 0, None)\n",
    "        return new_is_muted\n",
    "\n",
    "class VideoProcessor(threading.Thread):\n",
    "    \n",
    "    FINGER_TIP_IDS = [mp.solutions.hands.HandLandmark.INDEX_FINGER_TIP, \n",
    "                      mp.solutions.hands.HandLandmark.MIDDLE_FINGER_TIP, \n",
    "                      mp.solutions.hands.HandLandmark.RING_FINGER_TIP, \n",
    "                      mp.solutions.hands.HandLandmark.PINKY_TIP]\n",
    "    \n",
    "    FINGER_PIP_IDS = [mp.solutions.hands.HandLandmark.INDEX_FINGER_PIP, \n",
    "                      mp.solutions.hands.HandLandmark.MIDDLE_FINGER_PIP, \n",
    "                      mp.solutions.hands.HandLandmark.RING_FINGER_PIP, \n",
    "                      mp.solutions.hands.HandLandmark.PINKY_PIP]\n",
    "\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__()\n",
    "        self.running = True\n",
    "        \n",
    "        self.mp_hands = mp.solutions.hands\n",
    "        self.hands = self.mp_hands.Hands(\n",
    "            static_image_mode=False, \n",
    "            model_complexity=1, \n",
    "            min_detection_confidence=0.5,\n",
    "            min_tracking_confidence=0.5,\n",
    "            max_num_hands=1\n",
    "        )\n",
    "        self.mp_drawing = mp.solutions.drawing_utils\n",
    "        \n",
    "        self.current_frame = None\n",
    "        self.volume_pct = 0\n",
    "        self.distance_text = \"Fingers: N/A\" \n",
    "        self.volume_changed = False\n",
    "\n",
    "    def _count_extended_fingers(self, hand_landmarks):\n",
    "        finger_count = 0\n",
    "        \n",
    "        lm_thumb_tip = hand_landmarks.landmark[mp.solutions.hands.HandLandmark.THUMB_TIP]\n",
    "        lm_thumb_ip = hand_landmarks.landmark[mp.solutions.hands.HandLandmark.THUMB_IP] \n",
    "        lm_thumb_mcp = hand_landmarks.landmark[mp.solutions.hands.HandLandmark.THUMB_MCP]\n",
    "        \n",
    "        lm_index_mcp = hand_landmarks.landmark[mp.solutions.hands.HandLandmark.INDEX_FINGER_MCP]\n",
    "        is_right_hand = lm_thumb_mcp.x > lm_index_mcp.x\n",
    "        \n",
    "        if (is_right_hand and lm_thumb_tip.x > lm_thumb_ip.x) or \\\n",
    "           (not is_right_hand and lm_thumb_tip.x < lm_thumb_ip.x):\n",
    "            finger_count += 1\n",
    "            \n",
    "        for tip_id, pip_id in zip(self.FINGER_TIP_IDS, self.FINGER_PIP_IDS):\n",
    "            lm_tip = hand_landmarks.landmark[tip_id]\n",
    "            lm_pip = hand_landmarks.landmark[pip_id]\n",
    "            \n",
    "            if lm_tip.y < lm_pip.y:\n",
    "                finger_count += 1\n",
    "                \n",
    "        return finger_count\n",
    "\n",
    "    def run(self):\n",
    "        self.cap = cv2.VideoCapture(0)\n",
    "        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "        \n",
    "        frame_width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        frame_height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        \n",
    "        while self.running:\n",
    "            success, img = self.cap.read()\n",
    "            if not success:\n",
    "                time.sleep(0.01)\n",
    "                continue\n",
    "\n",
    "            img = cv2.flip(img, 1)\n",
    "            imgRGB = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            results = self.hands.process(imgRGB)\n",
    "            \n",
    "            self.volume_changed = False\n",
    "            new_volume_pct = self.volume_pct\n",
    "\n",
    "            if results.multi_hand_landmarks:\n",
    "                hand_landmarks = results.multi_hand_landmarks[0]\n",
    "                \n",
    "                finger_count = self._count_extended_fingers(hand_landmarks)\n",
    "                \n",
    "                new_volume_pct = int(finger_count * 20)\n",
    "                \n",
    "                lm_wrist = hand_landmarks.landmark[mp.solutions.hands.HandLandmark.WRIST]\n",
    "                wx, wy = int(lm_wrist.x * frame_width), int(lm_wrist.y * frame_height)\n",
    "                cv2.circle(img, (wx, wy), 10, (0, 255, 0), cv2.FILLED)\n",
    "                \n",
    "                self.mp_drawing.draw_landmarks(img, hand_landmarks, self.mp_hands.HAND_CONNECTIONS)\n",
    "                cv2.putText(img, f'MIC VOL: {new_volume_pct}%', (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "\n",
    "                self.distance_text = f\"Fingers: {finger_count}/5\"\n",
    "                self.volume_changed = True\n",
    "\n",
    "            else:\n",
    "                self.distance_text = \"Fingers: No Hand Detected\"\n",
    "\n",
    "            self.current_frame = img\n",
    "            self.volume_pct = new_volume_pct\n",
    "            \n",
    "            time.sleep(0.02) \n",
    "\n",
    "    def stop(self):\n",
    "        self.running = False\n",
    "        if hasattr(self, 'cap') and self.cap.isOpened():\n",
    "            self.cap.release()\n",
    "\n",
    "class GestureVolumeApp:\n",
    "    def __init__(self, window, window_title):\n",
    "        self.window = window\n",
    "        self.window.title(window_title)\n",
    "        \n",
    "        self.volume_handler = PycawVolumeHandler()\n",
    "        self.current_volume_pct, self.is_muted = self.volume_handler.get_initial_state()\n",
    "        \n",
    "        self.processor = VideoProcessor()\n",
    "        self.processor.start()\n",
    "        \n",
    "        self.setup_gui()\n",
    "        \n",
    "        self.delay = 30\n",
    "        self.update()\n",
    "\n",
    "        self.window.protocol(\"WM_DELETE_WINDOW\", self.on_closing)\n",
    "        self.window.mainloop()\n",
    "\n",
    "    def setup_gui(self):\n",
    "        self.distance_var = tk.StringVar(self.window, value=\"Fingers: N/A\")\n",
    "        self.volume_var = tk.StringVar(self.window, value=str(self.current_volume_pct))\n",
    "        self.mute_text_var = tk.StringVar(self.window)\n",
    "        \n",
    "        style = ttk.Style()\n",
    "        style.theme_use('clam')\n",
    "        \n",
    "        main_frame = ttk.Frame(self.window, padding=\"10 10 10 10\")\n",
    "        main_frame.pack(fill='both', expand=True)\n",
    "        \n",
    "        self.video_label = ttk.Label(main_frame, borderwidth=2, relief=\"groove\")\n",
    "        self.video_label.pack(pady=10)\n",
    "        \n",
    "        Label(main_frame, text=\"Microphone Volume:\").pack(pady=(5, 0))\n",
    "        self.volume_scale = Scale(\n",
    "            main_frame, \n",
    "            from_=0, to=100, orient=HORIZONTAL, length=300, resolution=1,\n",
    "            variable=self.volume_var, state='disabled',\n",
    "            troughcolor=\"#A0E0FF\", highlightbackground=\"#CCCCCC\"\n",
    "        )\n",
    "        self.volume_scale.pack(pady=5)\n",
    "        \n",
    "        distance_frame = ttk.Frame(main_frame)\n",
    "        distance_frame.pack(fill='x', pady=5)\n",
    "        ttk.Label(distance_frame, text=\"Finger Count:\", font=('Arial', 12)).pack(side='left', padx=(20, 5)) \n",
    "        self.distance_info_label = ttk.Label(\n",
    "            distance_frame, textvariable=self.distance_var,\n",
    "            font=('Arial', 14, 'bold'), foreground='#1E88E5'\n",
    "        )\n",
    "        self.distance_info_label.pack(side='left', fill='x', expand=True)\n",
    "\n",
    "        self.mute_button = Button(\n",
    "            main_frame, textvariable=self.mute_text_var, command=self.toggle_mute,\n",
    "            fg=\"white\", relief=\"raised\", font=('Arial', 10, 'bold')\n",
    "        )\n",
    "        self.mute_button.pack(fill='x', pady=10)\n",
    "        \n",
    "        self._update_mute_button_text()\n",
    "        \n",
    "        ttk.Label(\n",
    "            main_frame, \n",
    "            text=\"Control MIC volume by the number of fingers extended (0=0%, 5=100%).\",\n",
    "            font=('Arial', 10, 'italic')\n",
    "        ).pack(pady=5)\n",
    "\n",
    "    def _update_mute_button_text(self):\n",
    "        if self.is_muted:\n",
    "            self.mute_text_var.set(\"UNMUTE (Muted)\")\n",
    "            self.mute_button.config(bg=\"#FF6666\", activebackground=\"#DD4444\")\n",
    "        else:\n",
    "            self.mute_text_var.set(\"MUTE (Active)\")\n",
    "            self.mute_button.config(bg=\"#66FF66\", activebackground=\"#44DD44\")\n",
    "            \n",
    "    def toggle_mute(self):\n",
    "        self.is_muted = self.volume_handler.toggle_mute_state(self.is_muted)\n",
    "        self._update_mute_button_text()\n",
    "\n",
    "    def update(self):\n",
    "        \n",
    "        if self.processor.current_frame is not None:\n",
    "            img = self.processor.current_frame\n",
    "            self.photo = ImageTk.PhotoImage(image=Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB)))\n",
    "            self.video_label.config(image=self.photo)\n",
    "            \n",
    "            self.distance_var.set(self.processor.distance_text)\n",
    "\n",
    "        if self.processor.volume_changed:\n",
    "            new_volume_pct = self.processor.volume_pct\n",
    "            \n",
    "            self.volume_var.set(str(new_volume_pct))\n",
    "            \n",
    "            self.is_muted = self.volume_handler.set_volume_and_handle_mute(\n",
    "                new_volume_pct, self.is_muted\n",
    "            )\n",
    "            self.processor.volume_changed = False\n",
    "            self._update_mute_button_text()\n",
    "            \n",
    "        self.window.after(self.delay, self.update)\n",
    "        \n",
    "    def on_closing(self):\n",
    "        print(\"Stopping video processor thread and closing application...\")\n",
    "        self.processor.stop()\n",
    "        self.processor.join()\n",
    "        cv2.destroyAllWindows()\n",
    "        self.window.destroy()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root = tk.Tk()\n",
    "    app = GestureVolumeApp(root, \"Gesture Microphone Control (Finger Count)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f64b02b-711f-4795-b7fc-40571bd89a7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Volume Control)",
   "language": "python",
   "name": "volume_control"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
